#!/usr/bin/env python3
"""
Cria um arquivo CSV consolidado combinando todos os metadados extra√≠dos.
√ötil para an√°lises globais de todos os voos.
Usa apenas bibliotecas padr√£o do Python (sem depend√™ncias externas).
"""

import csv
from pathlib import Path
from collections import defaultdict
from datetime import datetime

def read_csv_file(csv_path):
    """L√™ um arquivo CSV e retorna lista de dicion√°rios."""
    rows = []
    with open(csv_path, 'r', encoding='utf-8') as f:
        reader = csv.DictReader(f)
        for row in reader:
            rows.append(row)
    return rows

def safe_float(value):
    """Converte valor para float de forma segura."""
    try:
        return float(value) if value else None
    except (ValueError, TypeError):
        return None

def create_consolidated_csv():
    """
    Cria um arquivo CSV √∫nico com todos os metadados de todos os v√≠deos.
    Adiciona uma coluna 'video_name' para identificar a origem.
    """
    base_dir = Path(__file__).parent / 'extracted_metadata'
    
    # Encontra todos os arquivos CSV de metadados
    csv_files = list(base_dir.glob('*/*_metadata.csv'))
    
    if not csv_files:
        print("‚ö†Ô∏è  Nenhum arquivo CSV encontrado em extracted_metadata/")
        return
    
    print(f"üìÅ Encontrados {len(csv_files)} arquivo(s) CSV\n")
    
    all_rows = []
    video_stats = defaultdict(lambda: {'count': 0, 'latitudes': [], 'longitudes': [], 
                                       'altitudes': [], 'timestamps': []})
    
    for csv_file in sorted(csv_files):
        # Extrai o nome do v√≠deo da pasta pai
        video_name = csv_file.parent.name
        print(f"üîÑ Processando: {video_name}")
        
        try:
            # Carrega o CSV
            rows = read_csv_file(csv_file)
            
            # Adiciona coluna video_name e coleta estat√≠sticas
            for row in rows:
                row['video_name'] = video_name
                all_rows.append(row)
                
                # Coleta estat√≠sticas
                video_stats[video_name]['count'] += 1
                lat = safe_float(row.get('latitude'))
                lon = safe_float(row.get('longitude'))
                alt = safe_float(row.get('relative_altitude'))
                
                if lat:
                    video_stats[video_name]['latitudes'].append(lat)
                if lon:
                    video_stats[video_name]['longitudes'].append(lon)
                if alt:
                    video_stats[video_name]['altitudes'].append(alt)
                if row.get('timestamp'):
                    video_stats[video_name]['timestamps'].append(row['timestamp'])
            
            print(f"   ‚úÖ {len(rows)} frames adicionados")
            
        except Exception as e:
            print(f"   ‚ùå Erro ao processar {csv_file}: {str(e)}")
    
    if not all_rows:
        print("\n‚ö†Ô∏è  Nenhum dado foi carregado!")
        return
    
    # Define ordem das colunas (video_name no in√≠cio)
    fieldnames = ['video_name', 'frame_index', 'timestamp', 'latitude', 'longitude',
                  'relative_altitude', 'absolute_altitude', 'iso', 'shutter', 
                  'aperture', 'ev', 'color_mode', 'focal_length', 'color_temperature']
    
    # Ordena por v√≠deo e frame_index
    def sort_key(row):
        video = row.get('video_name', '')
        try:
            frame_idx = int(row.get('frame_index', 0))
        except (ValueError, TypeError):
            frame_idx = 0
        return (video, frame_idx)
    
    all_rows.sort(key=sort_key)
    
    # Salva o arquivo consolidado
    output_file = base_dir / 'all_metadata_consolidated.csv'
    with open(output_file, 'w', newline='', encoding='utf-8') as f:
        writer = csv.DictWriter(f, fieldnames=fieldnames)
        writer.writeheader()
        
        for row in all_rows:
            # Garante que todas as colunas existam
            output_row = {col: row.get(col, '') for col in fieldnames}
            writer.writerow(output_row)
    
    print(f"\n‚úÖ Arquivo consolidado criado: {output_file}")
    print(f"   Total de frames: {len(all_rows):,}")
    print(f"   Total de v√≠deos: {len(video_stats)}")
    
    # Estat√≠sticas por v√≠deo
    print("\nüìä Estat√≠sticas por v√≠deo:")
    print("-" * 80)
    
    # Calcula estat√≠sticas globais
    all_lats = []
    all_lons = []
    all_alts = []
    
    # Cria arquivo de estat√≠sticas
    stats_file = base_dir / 'statistics_summary.txt'
    with open(stats_file, 'w', encoding='utf-8') as f:
        f.write("Estat√≠sticas Consolidadas dos Metadados Extra√≠dos\n")
        f.write("=" * 80 + "\n\n")
        f.write(f"Total de frames: {len(all_rows):,}\n")
        f.write(f"Total de v√≠deos: {len(video_stats)}\n\n")
        f.write("Frames por v√≠deo:\n")
        f.write("-" * 80 + "\n")
        
        for video in sorted(video_stats.keys()):
            stats = video_stats[video]
            count = stats['count']
            f.write(f"{video}: {count:,} frames\n")
            print(f"{video}: {count:,} frames")
            
            # Coleta dados globais
            all_lats.extend(stats['latitudes'])
            all_lons.extend(stats['longitudes'])
            all_alts.extend(stats['altitudes'])
        
        f.write("\n" + "=" * 80 + "\n")
        f.write("\nEstat√≠sticas Detalhadas por V√≠deo:\n")
        f.write("-" * 80 + "\n")
        
        for video in sorted(video_stats.keys()):
            stats = video_stats[video]
            f.write(f"\n{video}:\n")
            f.write(f"  Frames: {stats['count']}\n")
            
            if stats['latitudes']:
                f.write(f"  Latitude: {min(stats['latitudes']):.6f} a {max(stats['latitudes']):.6f}\n")
            if stats['longitudes']:
                f.write(f"  Longitude: {min(stats['longitudes']):.6f} a {max(stats['longitudes']):.6f}\n")
            if stats['altitudes']:
                avg_alt = sum(stats['altitudes']) / len(stats['altitudes'])
                f.write(f"  Altitude Relativa: {min(stats['altitudes']):.2f} a {max(stats['altitudes']):.2f} m (m√©dia: {avg_alt:.2f} m)\n")
            if stats['timestamps']:
                f.write(f"  Timestamp inicial: {min(stats['timestamps'])}\n")
                f.write(f"  Timestamp final: {max(stats['timestamps'])}\n")
        
        f.write("\n" + "=" * 80 + "\n")
        f.write("\nEstat√≠sticas Globais:\n")
        f.write("-" * 80 + "\n")
        
        if all_lats:
            f.write(f"Latitude m√≠nima: {min(all_lats):.6f}\n")
            f.write(f"Latitude m√°xima: {max(all_lats):.6f}\n")
        if all_lons:
            f.write(f"Longitude m√≠nima: {min(all_lons):.6f}\n")
            f.write(f"Longitude m√°xima: {max(all_lons):.6f}\n")
        if all_alts:
            avg_alt_global = sum(all_alts) / len(all_alts)
            f.write(f"\nAltitude Relativa:\n")
            f.write(f"  M√≠nima: {min(all_alts):.2f} m\n")
            f.write(f"  M√°xima: {max(all_alts):.2f} m\n")
            f.write(f"  M√©dia: {avg_alt_global:.2f} m\n")
    
    print(f"\n‚úÖ Estat√≠sticas salvas em: {stats_file}")
    print("\n" + "=" * 80)
    print("‚úÖ Processamento conclu√≠do!")

if __name__ == '__main__':
    print("üöÄ Criando CSV consolidado de todos os metadados\n")
    create_consolidated_csv()

